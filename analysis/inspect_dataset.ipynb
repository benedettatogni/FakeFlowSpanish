{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting features and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply RoBERTa classifier to test set:\n",
    "# roberta_test_df = utils.apply_roberta(\"../data/fakedes/test.tsv\")\n",
    "# roberta_test_df.to_csv(\"../outputs/roberta_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get performance using RoBERTa classifier:\n",
    "# roberta_test_df = pd.read_csv(\"../outputs/roberta_results.csv\")\n",
    "# roberta_test_df[\"predicted_label\"] = roberta_test_df[\"predicted_label\"].replace({\"REAL\": 0, \"FAKE\": 1})\n",
    "# roberta_test_df[\"prediction\"] = roberta_test_df[\"predicted_label\"]\n",
    "# roberta_test_df[\"label\"] = roberta_test_df[\"CATEGORY\"]\n",
    "# roberta_test_df[\"label\"] = roberta_test_df[\"label\"].replace({True: 0, False: 1})\n",
    "# roberta_test_df[\"source\"] = roberta_test_df[\"SOURCE\"].fillna(\"\")\n",
    "# # Get performance on test set:\n",
    "# utils.test_performance(roberta_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the dataset and features for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = [\"anger\", \"anticipation\", \"disgust\", \"fear\",\n",
    "                  \"joy\", \"sadness\", \"surprise\", \"trust\",\n",
    "                  \"positive\", \"negative\", \"valence\", \"arousal\",\n",
    "                  \"concreteness\", \"imageability\", \"hyperbolic\",\n",
    "                  \"hurtful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets:\n",
    "data_df = []\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    data_df.append(utils.merge_data_outputs(split, feature_labels))\n",
    "\n",
    "train_df, dev_df, test_df = data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(dev_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Train: fake ===\")\n",
    "print(train_df[train_df[\"label\"] == 1].topic.value_counts())\n",
    "print(train_df[train_df[\"label\"] == 1].shape)\n",
    "print(\"\\n=== Train: true ===\")\n",
    "print(train_df[train_df[\"label\"] == 0].topic.value_counts())\n",
    "print(train_df[train_df[\"label\"] == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Dev: fake ===\")\n",
    "print(dev_df[dev_df[\"label\"] == 1].topic.value_counts())\n",
    "print(dev_df[dev_df[\"label\"] == 1].shape)\n",
    "print(\"\\n=== Dev: true ===\")\n",
    "print(dev_df[dev_df[\"label\"] == 0].topic.value_counts())\n",
    "print(dev_df[dev_df[\"label\"] == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Test: fake ===\")\n",
    "print(test_df[test_df[\"label\"] == 1].topic.value_counts())\n",
    "print(test_df[test_df[\"label\"] == 1].shape)\n",
    "print(\"\\n=== Test: true ===\")\n",
    "print(test_df[test_df[\"label\"] == 0].topic.value_counts())\n",
    "print(test_df[test_df[\"label\"] == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join train and dev for the analyses:\n",
    "train_df = pd.concat([train_df, dev_df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show contents of the first row:\n",
    "test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore features position (figure 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EMOTIONS\n",
    "## ============================================================\n",
    "\n",
    "topic = \"all\" # \"all\", \"covid-19\", \"politics\", \"entertainment\"\n",
    "dsplit = \"all\" # \"train\", \"test\"\n",
    "\n",
    "tmp_flow_df = pd.concat([train_df, test_df], sort=True)\n",
    "\n",
    "fake_df = tmp_flow_df[tmp_flow_df[\"label\"] == 1]\n",
    "true_df = tmp_flow_df[tmp_flow_df[\"label\"] == 0]\n",
    "\n",
    "if topic != \"all\":\n",
    "    # Only per topic:\n",
    "    fake_df = fake_df[fake_df[\"topic\"] == topic]\n",
    "    true_df = true_df[true_df[\"topic\"] == topic]\n",
    "\n",
    "# Keep only emotions:\n",
    "fake_features_array = np.array(fake_df.features.values.tolist()).mean(0)\n",
    "true_features_array = np.array(true_df.features.values.tolist()).mean(0)\n",
    "\n",
    "moving_average_window = 2\n",
    "fake_segment_mean = moving_average(fake_features_array.mean(axis=1), 2)\n",
    "true_segment_mean = moving_average(true_features_array.mean(axis=1), 2)\n",
    "# Keep only emotions (eight first features):\n",
    "fake_features_array = np.array(fake_df.features.values.tolist()).mean(0)[:, :8]\n",
    "true_features_array = np.array(true_df.features.values.tolist()).mean(0)[:, :8]\n",
    "\n",
    "current_features = feature_labels[:8]\n",
    "# Plot features:\n",
    "for feat_i in range(len(current_features)):\n",
    "    segment_features_true = true_features_array[:, feat_i] # All features per segments\n",
    "    segment_features_true = moving_average(segment_features_true, moving_average_window)\n",
    "    segment_features_fake = fake_features_array[:, feat_i] # All features per segments\n",
    "    segment_features_fake = moving_average(segment_features_fake, moving_average_window)\n",
    "    x_axis = [x for x in range(1, len(segment_features_true) + 1)]\n",
    "    plt.figure(figsize=(9,2))\n",
    "    plt.plot(x_axis, segment_features_fake, color=\"red\", label=\"fake\")\n",
    "    plt.plot(x_axis, segment_features_true, color=\"green\", label=\"true\")\n",
    "    plt.plot(x_axis, fake_segment_mean, color=\"lightcoral\", label=\"fake avg\", linestyle=\"dotted\")\n",
    "    plt.plot(x_axis, true_segment_mean, color=\"lightseagreen\", label=\"true avg\", linestyle=\"dotted\")\n",
    "    plt.xticks(x_axis)\n",
    "    plt.title(current_features[feat_i].title())\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(\"figures/features_x_segment_\" + current_features[feat_i] + \"_\" + dsplit + \"_\" + topic + \".png\", dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEMANTICO-AFFECTIVE\n",
    "## ============================================================\n",
    "\n",
    "topic = \"all\" # \"all\", \"covid-19\", \"politics\", \"entertainment\"\n",
    "dsplit = \"all\" # \"train\", \"test\"\n",
    "\n",
    "tmp_flow_df = pd.concat([train_df, test_df], sort=True)\n",
    "\n",
    "fake_df = tmp_flow_df[tmp_flow_df[\"label\"] == 1]\n",
    "true_df = tmp_flow_df[tmp_flow_df[\"label\"] == 0]\n",
    "\n",
    "if topic != \"all\":\n",
    "    # Only per topic:\n",
    "    fake_df = fake_df[fake_df[\"topic\"] == topic]\n",
    "    true_df = true_df[true_df[\"topic\"] == topic]\n",
    "\n",
    "# Keep only emotions:\n",
    "fake_features_array = np.array(fake_df.features.values.tolist()).mean(0)\n",
    "true_features_array = np.array(true_df.features.values.tolist()).mean(0)\n",
    "\n",
    "moving_average_window = 2\n",
    "fake_segment_mean = moving_average(fake_features_array.mean(axis=1), 2)\n",
    "true_segment_mean = moving_average(true_features_array.mean(axis=1), 2)\n",
    "# Keep only semantico-affective features (features 11 to 14):\n",
    "fake_features_array = np.array(fake_df.features.values.tolist()).mean(0)[:, 10:14]\n",
    "true_features_array = np.array(true_df.features.values.tolist()).mean(0)[:, 10:14]\n",
    "\n",
    "current_features = feature_labels[10:14]\n",
    "# Plot features:\n",
    "for feat_i in range(len(current_features)):\n",
    "    x_axis = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    segment_features_true = true_features_array[:, feat_i] # All features per segments\n",
    "    segment_features_true = moving_average(segment_features_true, moving_average_window)\n",
    "    segment_features_fake = fake_features_array[:, feat_i] # All features per segments\n",
    "    segment_features_fake = moving_average(segment_features_fake, moving_average_window)\n",
    "    x_axis = [x for x in range(1, len(segment_features_true) + 1)]\n",
    "    plt.figure(figsize=(9,2))\n",
    "    plt.plot(x_axis, segment_features_fake, color=\"red\", label=\"fake\")\n",
    "    plt.plot(x_axis, segment_features_true, color=\"green\", label=\"true\")\n",
    "    plt.plot(x_axis, fake_segment_mean, color=\"lightcoral\", label=\"fake avg\", linestyle=\"dotted\")\n",
    "    plt.plot(x_axis, true_segment_mean, color=\"lightseagreen\", label=\"true avg\", linestyle=\"dotted\")\n",
    "    plt.xticks(x_axis)\n",
    "    plt.title(current_features[feat_i].title())\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(\"figures/features_x_segment_\" + current_features[feat_i] + \"_\" + dsplit + \"_\" + topic + \".png\", dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SENTIMENT\n",
    "## ============================================================\n",
    "\n",
    "topic = \"all\" # \"all\", \"covid-19\", \"politics\", \"entertainment\"\n",
    "dsplit = \"all\" # \"train\", \"test\"\n",
    "\n",
    "tmp_flow_df = pd.concat([train_df, test_df], sort=True)\n",
    "\n",
    "fake_df = tmp_flow_df[tmp_flow_df[\"label\"] == 1]\n",
    "true_df = tmp_flow_df[tmp_flow_df[\"label\"] == 0]\n",
    "\n",
    "if topic != \"all\":\n",
    "    # Only per topic:\n",
    "    fake_df = fake_df[fake_df[\"topic\"] == topic]\n",
    "    true_df = true_df[true_df[\"topic\"] == topic]\n",
    "\n",
    "# Keep only emotions:\n",
    "fake_features_array = np.array(fake_df.features.values.tolist()).mean(0)\n",
    "true_features_array = np.array(true_df.features.values.tolist()).mean(0)\n",
    "\n",
    "moving_average_window = 2\n",
    "fake_segment_mean = moving_average(fake_features_array.mean(axis=1), 2)\n",
    "true_segment_mean = moving_average(true_features_array.mean(axis=1), 2)\n",
    "# Keep only sentiment features (features 9 and 10):\n",
    "fake_features_array = np.array(fake_df.features.values.tolist()).mean(0)[:, 8:10]\n",
    "true_features_array = np.array(true_df.features.values.tolist()).mean(0)[:, 8:10]\n",
    "\n",
    "current_features = feature_labels[8:10]\n",
    "# Plot features:\n",
    "for feat_i in range(len(current_features)):\n",
    "    x_axis = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    segment_features_true = true_features_array[:, feat_i] # All features per segments\n",
    "    segment_features_true = moving_average(segment_features_true, moving_average_window)\n",
    "    segment_features_fake = fake_features_array[:, feat_i] # All features per segments\n",
    "    segment_features_fake = moving_average(segment_features_fake, moving_average_window)\n",
    "    x_axis = [x for x in range(1, len(segment_features_true) + 1)]\n",
    "    plt.figure(figsize=(9,2))\n",
    "    plt.plot(x_axis, segment_features_fake, color=\"red\", label=\"fake\")\n",
    "    plt.plot(x_axis, segment_features_true, color=\"green\", label=\"true\")\n",
    "    plt.plot(x_axis, fake_segment_mean, color=\"lightcoral\", label=\"fake avg\", linestyle=\"dotted\")\n",
    "    plt.plot(x_axis, true_segment_mean, color=\"lightseagreen\", label=\"true avg\", linestyle=\"dotted\")\n",
    "    plt.xticks(x_axis)\n",
    "    plt.title(current_features[feat_i].title())\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(\"figures/features_x_segment_\" + current_features[feat_i] + \"_\" + dsplit + \"_\" + topic + \".png\", dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERBOLIC-HURTFUL\n",
    "## ============================================================\n",
    "\n",
    "topic = \"all\" # \"all\", \"covid-19\", \"politics\", \"entertainment\"\n",
    "dsplit = \"all\" # \"train\", \"test\"\n",
    "\n",
    "tmp_flow_df = pd.concat([train_df, test_df], sort=True)\n",
    "\n",
    "fake_df = tmp_flow_df[tmp_flow_df[\"label\"] == 1]\n",
    "true_df = tmp_flow_df[tmp_flow_df[\"label\"] == 0]\n",
    "\n",
    "if topic != \"all\":\n",
    "    # Only per topic:\n",
    "    fake_df = fake_df[fake_df[\"topic\"] == topic]\n",
    "    true_df = true_df[true_df[\"topic\"] == topic]\n",
    "\n",
    "# Keep only emotions:\n",
    "fake_features_array = np.array(fake_df.features.values.tolist()).mean(0)\n",
    "true_features_array = np.array(true_df.features.values.tolist()).mean(0)\n",
    "\n",
    "moving_average_window = 2\n",
    "fake_segment_mean = moving_average(fake_features_array.mean(axis=1), 2)\n",
    "true_segment_mean = moving_average(true_features_array.mean(axis=1), 2)\n",
    "# Keep only semantico-affective features (features 15 and 16):\n",
    "fake_features_array = np.array(fake_df.features.values.tolist()).mean(0)[:, 14:16]\n",
    "true_features_array = np.array(true_df.features.values.tolist()).mean(0)[:, 14:16]\n",
    "\n",
    "current_features = feature_labels[14:16]\n",
    "# Plot features:\n",
    "for feat_i in range(len(current_features)):\n",
    "    x_axis = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    segment_features_true = true_features_array[:, feat_i] # All features per segments\n",
    "    segment_features_true = moving_average(segment_features_true, moving_average_window)\n",
    "    segment_features_fake = fake_features_array[:, feat_i] # All features per segments\n",
    "    segment_features_fake = moving_average(segment_features_fake, moving_average_window)\n",
    "    x_axis = [x for x in range(1, len(segment_features_true) + 1)]\n",
    "    plt.figure(figsize=(9,2))\n",
    "    plt.plot(x_axis, segment_features_fake, color=\"red\", label=\"fake\")\n",
    "    plt.plot(x_axis, segment_features_true, color=\"green\", label=\"true\")\n",
    "    plt.plot(x_axis, fake_segment_mean, color=\"lightcoral\", label=\"fake avg\", linestyle=\"dotted\")\n",
    "    plt.plot(x_axis, true_segment_mean, color=\"lightseagreen\", label=\"true avg\", linestyle=\"dotted\")\n",
    "    plt.xticks(x_axis)\n",
    "    plt.title(current_features[feat_i].title())\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(\"figures/features_x_segment_\" + current_features[feat_i] + \"_\" + dsplit + \"_\" + topic + \".png\", dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radar plot per topic (figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_fake = [0, 1]\n",
    "topics = [\"politics\", \"entertainment\", \"covid-19\"]\n",
    "features_for_radar = [\"anger\", \"anticipation\", \"disgust\", \"fear\",\n",
    "                  \"joy\", \"sadness\", \"surprise\", \"trust\", \"hurtful\"]\n",
    "\n",
    "dDataForRadar_true = dict()\n",
    "dDataForRadar_fake = dict()\n",
    "for type_news in true_fake:\n",
    "    dDataForRadar = dict()\n",
    "    for dsplit in [\"train\", \"test\"]:\n",
    "        tmp_df = train_df if dsplit == \"train\" else test_df\n",
    "        if type_news == 0:\n",
    "            tmp_df = tmp_df[tmp_df[\"label\"] == 0]\n",
    "        elif type_news == 1:\n",
    "            tmp_df = tmp_df[tmp_df[\"label\"] == 1]\n",
    "        data_for_radar_tmp = []\n",
    "        for topic in topics:\n",
    "            tmp_df_tmp = tmp_df.copy()\n",
    "            tmp_df_tmp = tmp_df_tmp[tmp_df_tmp[\"topic\"] == topic]\n",
    "            if tmp_df_tmp.shape[0] < 10:\n",
    "                print(\"No data for:\", dsplit, \"-\", type_news, \"-\", topic)\n",
    "                new_list = [0.00 for f in features_for_radar]\n",
    "            else:\n",
    "                x_train = tmp_df_tmp[features_for_radar]\n",
    "                y_train = tmp_df_tmp[\"label\"]\n",
    "                new_list = []\n",
    "                for f in features_for_radar:\n",
    "                    new_list.append(round(np.mean(x_train[f]), 4))\n",
    "            data_for_radar_tmp.append(new_list)\n",
    "        if type_news == 0:\n",
    "            dDataForRadar_true[dsplit] = [topics, features_for_radar, data_for_radar_tmp]\n",
    "        elif type_news == 1:\n",
    "            dDataForRadar_fake[dsplit] = [topics, features_for_radar, data_for_radar_tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_data():\n",
    "    data = [\n",
    "        data_to_plot[\"train\"][1],\n",
    "        ('Training set', data_to_plot[\"train\"][2]),\n",
    "        ('Test set', data_to_plot[\"test\"][2])\n",
    "    ]\n",
    "    return data\n",
    "\n",
    "for dsplit in [\"true\", \"fake\"]:\n",
    "    print(dsplit)\n",
    "\n",
    "    data_to_plot = dDataForRadar_fake\n",
    "    if dsplit == \"true\":\n",
    "        data_to_plot = dDataForRadar_true\n",
    "        \n",
    "    N = len(data_to_plot[\"train\"][1])\n",
    "    theta = utils.radar_factory(N, frame='polygon')\n",
    "    data = example_data()\n",
    "    spoke_labels = data.pop(0)\n",
    "\n",
    "    print(data)\n",
    "    print(spoke_labels)\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(9, 4.5), ncols=2, nrows=1, subplot_kw=dict(projection='radar'))\n",
    "    fig.subplots_adjust(wspace=0.35, hspace=0.0, top=0.95, bottom=0.05)\n",
    "\n",
    "    colors = ['g', 'r', 'c']\n",
    "    for ax, (title, case_data) in zip(axs.flat, data):\n",
    "        ax.set_rgrids([0.02, 0.04, 0.06, 0.08, 0.1])\n",
    "        ax.set_title(title, weight='bold', size='medium', position=(0.5, 1.1),\n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        ax.set_ylim(0, 0.09)\n",
    "        for d, color in zip(case_data, colors):\n",
    "            ax.plot(theta, d, color=color)\n",
    "            ax.fill(theta, d, facecolor=color, alpha=0.25, label='_nolegend_')\n",
    "        ax.set_varlabels(spoke_labels)\n",
    "\n",
    "    labels = (data_to_plot[\"train\"][0])\n",
    "    legend = axs[0].legend(labels, loc=(0.95, 0.95), labelspacing=0.1, fontsize='small')\n",
    "\n",
    "    plt.savefig(\"figures/radar_\" + dsplit + \"_sum.png\", dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect segments attention (figure4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (test_df[\"prediction\"] == 0) & (test_df[\"label\"] == 0)\n",
    "results_both_w_attn_df_pred0 = test_df[mask]\n",
    "attention_array_both = np.array(results_both_w_attn_df_pred0.attention_scores.values.tolist()).astype(float)\n",
    "attention_mean_matrix_both = attention_array_both.mean(axis=0)\n",
    "plt.imshow(attention_mean_matrix_both, interpolation='none', extent=[1, 10, 10, 1])\n",
    "plt.clim(0.0991, 0.1015)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Segment\")\n",
    "plt.xticks(x_axis)\n",
    "plt.savefig(\"figures/self_attention_true_label.png\", dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "in_parts = attention_mean_matrix_both.mean(axis=0)\n",
    "print(in_parts[:3].mean())\n",
    "print(in_parts[3:7].mean())\n",
    "print(in_parts[7:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (test_df[\"prediction\"] == 1) & (test_df[\"label\"] == 1)\n",
    "results_both_w_attn_df_pred1 = test_df[mask]\n",
    "attention_array_both = np.array(results_both_w_attn_df_pred1.attention_scores.values.tolist()).astype(float)\n",
    "attention_mean_matrix_both = attention_array_both.mean(axis=0)\n",
    "plt.imshow(attention_mean_matrix_both, interpolation='none', extent=[1, 10, 10, 1])\n",
    "plt.clim(0.0991, 0.1015)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Segment\")\n",
    "plt.xticks(x_axis)\n",
    "plt.savefig(\"figures/self_attention_true_label.png\", dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "in_parts = attention_mean_matrix_both.mean(axis=0)\n",
    "print(in_parts[:3].mean())\n",
    "print(in_parts[3:7].mean())\n",
    "print(in_parts[7:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = test_df.copy()\n",
    "doc_row = tmp_df.iloc[369]\n",
    "text_doc = doc_row.text\n",
    "text_segments = [\" \".join(x.tolist()) for x in np.array_split(text_doc.replace(\"\\n\", \" \").replace(\"  \", \" \").split(\" \"), 10)][:5]\n",
    "text_for_viz = \"\"\"\n",
    "{}\n",
    "\"\"\".format(\"\\n\".join([x[:150] for x in text_segments])).lstrip()\n",
    "text_attention = np.array(doc_row[\"attention_scores\"]).astype(float)\n",
    "emotions_to_highlight, sem_aff_features = utils.highlight_emotions(text_segments)\n",
    "text_attention_vector = text_attention.mean(axis=0)\n",
    "scaled_mat = (text_attention_vector - np.min(text_attention_vector)) / (np.max(text_attention_vector) - np.min(text_attention_vector)) * 0.9\n",
    "attn_grey_indices = [int(round(x, 1)*10) for x in list(scaled_mat)][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_grey_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function color_emotions to highlight the words associated to emotions\n",
    "original_text = utils.color_emotions(text_for_viz, emotions_to_highlight)\n",
    "\n",
    "#Create HTML content with square_color as argument  \n",
    "html_content = utils.create_colored_html_with_rectangle(original_text, attn_grey_indices)\n",
    "\n",
    "#Visualize the HTML content\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature mean scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in feature_labels:\n",
    "    print(emotion)\n",
    "    print(\"train, true:\", round(train_df[(train_df[\"label\"] == 0) & (train_df[\"topic\"] == \"politics\")][emotion].mean(), 3))\n",
    "    print(\"train, fake:\", round(train_df[(train_df[\"label\"] == 1) & (train_df[\"topic\"] == \"politics\")][emotion].mean(), 3))\n",
    "    print(\"test, true:\", round(test_df[(test_df[\"label\"] == 0) & (test_df[\"topic\"] == \"politics\")][emotion].mean(), 3))\n",
    "    print(\"test, fake:\", round(test_df[(test_df[\"label\"] == 1) & (test_df[\"topic\"] == \"politics\")][emotion].mean(), 3))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
